{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96623f98-03c6-4f07-9627-7d563ee90542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install flask transformers torch\n",
    "# from flask import Flask, request, jsonify\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch\n",
    "\n",
    "# # Load the model and tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"./sarcasm_model\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"./sarcasm_model\")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Initialize Flask app\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# @app.route(\"/predict\", methods=[\"POST\"])\n",
    "# def predict():\n",
    "#     data = request.json\n",
    "#     text = data.get(\"text\", \"\")\n",
    "\n",
    "#     # Tokenize and process the input\n",
    "#     tokenized_input = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**tokenized_input)\n",
    "#         prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "#         label = \"Sarcastic\" if prediction == 1 else \"Not Sarcastic\"\n",
    "\n",
    "#     return jsonify({\"text\": text, \"prediction\": label})\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     app.run(host=\"0.0.0.0\", port=5002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46656c16-6541-4583-9825-c1fda53f9ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf740e8-226b-4d7b-afb4-d37ca160e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curl -X POST -H \"Content-Type: application/json\" \\\n",
    "# -d '{\"text\": \"I absolutely love waiting in long lines.\"}' \\\n",
    "# http://127.0.0.1:5002/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f2f1b9-9abd-49c2-be84-12abd02970e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 01:37:32.367 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.702 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/homebrew/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-12-02 01:37:32.702 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.702 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.703 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.703 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.703 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.703 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.703 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.704 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.704 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.704 Session state does not function when running a script without `streamlit run`\n",
      "2024-12-02 01:37:32.704 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.704 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-02 01:37:32.706 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./sarcasm_model\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./sarcasm_model\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Streamlit app UI\n",
    "st.title(\"Sarcasm Detection App\")\n",
    "st.write(\"Enter a sentence to check if it's sarcastic or not.\")\n",
    "\n",
    "# User input field\n",
    "text_input = st.text_area(\"Enter Text Here\")\n",
    "\n",
    "# Button to trigger prediction\n",
    "if st.button(\"Predict\"):\n",
    "    if text_input:\n",
    "        # Tokenize input text\n",
    "        tokenized_input = tokenizer(text_input, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "        # Model prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokenized_input)\n",
    "            prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "            label = \"Sarcastic\" if prediction == 1 else \"Not Sarcastic\"\n",
    "\n",
    "        # Display result\n",
    "        st.write(f\"Prediction: {label}\")\n",
    "    else:\n",
    "        st.write(\"Please enter some text to analyze.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01a594-f3ed-4450-afd6-2ec2bc8284ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
